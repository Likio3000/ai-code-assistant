--- START FILE: types.ts ---

export enum MessageRole {
  USER = "user",
  AI = "ai",
  SYSTEM = "system",
}

export enum MessageType {
  SUGGESTION = "suggestion",
  CODE = "code",
  ERROR = "error",
}

export interface Message {
  id: string;
  role: MessageRole;
  type: MessageType | null;
  content: string;
  agent?: string;
  isStreaming: boolean;
  originalUserMessage?: string;
}

export interface StreamEvent {
  type: 'suggestions_chunk' | 'suggestions_end' | 'generated_code_chunk' | 'stream_end' | 'error';
  content?: string;
  agent?: string;
  fullContent?: string;
}

--- END FILE: types.ts ---
--- START FILE: README.md ---
# Run and deploy your AI Studio app

This contains everything you need to run your app locally.

## Run Locally

**Prerequisites:**  Node.js


1. Install dependencies:
   `npm install`
2. Set the `GEMINI_API_KEY` in [.env.local](.env.local) to your Gemini API key
3. Run the app:
   `npm run dev`

--- END FILE: README.md ---
--- START FILE: package.json ---
{
  "name": "ai-code-assistant",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "react": "^19.1.1",
    "react-dom": "^19.1.1",
    "@google/genai": "^1.12.0"
  },
  "devDependencies": {
    "@types/node": "^22.14.0",
    "typescript": "~5.8.2",
    "vite": "^6.2.0"
  }
}

--- END FILE: package.json ---
--- START FILE: index.tsx ---

import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App';

const rootElement = document.getElementById('root');
if (!rootElement) {
  throw new Error("Could not find root element to mount to");
}

const root = ReactDOM.createRoot(rootElement);
root.render(
  <React.StrictMode>
    <App />
  </React.StrictMode>
);

--- END FILE: index.tsx ---
--- START FILE: index.html ---

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Code Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css"
    />
  <script type="importmap">
{
  "imports": {
    "react": "https://esm.sh/react@^19.1.1",
    "react-dom/": "https://esm.sh/react-dom@^19.1.1/",
    "react/": "https://esm.sh/react@^19.1.1/",
    "@google/genai": "https://esm.sh/@google/genai@^1.12.0"
  }
}
</script>
<link rel="stylesheet" href="/index.css">
</head>
  <body class="bg-slate-900">
    <div id="root"></div>

    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script type="module" src="/index.tsx"></script>
  </body>
</html>

--- END FILE: index.html ---
--- START FILE: tsconfig.json ---
{
  "compilerOptions": {
    "target": "ES2022",
    "experimentalDecorators": true,
    "useDefineForClassFields": false,
    "module": "ESNext",
    "lib": [
      "ES2022",
      "DOM",
      "DOM.Iterable"
    ],
    "skipLibCheck": true,
    "moduleResolution": "bundler",
    "isolatedModules": true,
    "moduleDetection": "force",
    "allowJs": true,
    "jsx": "react-jsx",
    "paths": {
      "@/*": [
        "./*"
      ]
    },
    "allowImportingTsExtensions": true,
    "noEmit": true
  }
}
--- END FILE: tsconfig.json ---
--- START FILE: .gitignore ---
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

node_modules
dist
dist-ssr
*.local

# Editor directories and files
.vscode/*
!.vscode/extensions.json
.idea
.DS_Store
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?

--- END FILE: .gitignore ---
--- START FILE: sc2.py ---
"""
sc2.py – collect the text source of a project into one big clipboard / file
         while honouring .gitignore and avoiding duplicate output.
"""

from __future__ import annotations

import argparse
import os
import sys
from pathlib import Path

# ---------- optional deps ---------- #
try:
    import pyperclip  # type: ignore
except ImportError:
    pyperclip = None
    print(
        "Note: Clipboard functionality ('pyperclip') is not available. Install it with 'uv add pyperclip'."
    )


try:
    import pathspec  # type: ignore
except ImportError:
    pathspec = None
# ----------------------------------- #

# --------- user‑tweakable knobs -------- #
ALLOWED_EXTENSIONS = {
    ".py",
    ".js",
    ".jsx",
    ".ts",
    ".tsx",
    ".html",
    ".htm",
    ".css",
    ".scss",
    ".sass",
    ".json",
    ".yaml",
    ".yml",
    ".xml",
    ".md",
    ".txt",
    ".sh",
    ".bash",
    ".zsh",
    ".java",
    ".cs",
    ".cpp",
    ".c",
    ".h",
    ".hpp",
    ".go",
    ".rs",
    ".php",
    ".rb",
    ".sql",
}

ALLOWED_FILENAMES = {
    "dockerfile",
    "docker-compose.yml",
    ".env.example",
    ".gitignore",
    "requirements.txt",
    "package.json",
    "composer.json",
    "pom.xml",
    "gemfile",
}

EXCLUDED_DIRS = {
    ".git",
    ".ruff_cache",
    ".svn",
    ".hg",
    "__pycache__",
    "node_modules",
    "vendor",
    "egg-info",
    "target",
    "build",
    "dist",
    "out",
    "bin",
    "obj",
    ".vscode",
    ".idea",
    ".next",
    ".venv",
    "venv",
    ".env",
    "env",
    "pipeline_runs_cs",
    "UI_alphas_lab"
}
EXCLUDED_DIRS = {d.lower() for d in EXCLUDED_DIRS}

EXCLUDED_FILES = {
    ".env",
    "credentials.json",
    "secrets.yaml",
    "package-lock.json",
    "yarn.lock",
    "composer.lock",
    "pythonCode.ts",
}
EXCLUDED_FILES = {f.lower() for f in EXCLUDED_FILES}

MAX_FILE_SIZE_BYTES = 1 * 1024 * 1024  # 1 MiB
DEFAULT_OUTPUT_FILE = "sc2_output.txt"
# -------------------------------------- #


def load_gitignore(project_dir: Path):
    if not pathspec:
        return None
    gi_path = project_dir / ".gitignore"
    if gi_path.exists():
        with gi_path.open(encoding="utf-8", errors="ignore") as fh:
            return pathspec.PathSpec.from_lines("gitwildmatch", fh)
    return None


def collect_project_contents(
    project_dir: Path,
    exclude_extra: set[str] | None = None,
    verbose: bool = False,
):
    gitignore_spec = load_gitignore(project_dir)
    visited: set[str] = set()
    pieces: list[str] = []

    exclude_names = EXCLUDED_FILES.union({x.lower() for x in exclude_extra or set()})

    for root, dirs, files in os.walk(project_dir, topdown=True):
        # prune unwanted dirs in‑place
        dirs[:] = [d for d in dirs if d.lower() not in EXCLUDED_DIRS]

        for filename in files:
            rel_path = os.path.relpath(os.path.join(root, filename), project_dir)
            rel_lower = rel_path.lower()

            if rel_lower in visited:
                continue
            visited.add(rel_lower)

            if filename.lower() in exclude_names:
                continue

            ext = Path(filename).suffix.lower()
            if (
                ext not in ALLOWED_EXTENSIONS
                and filename.lower() not in ALLOWED_FILENAMES
            ):
                continue

            if gitignore_spec and gitignore_spec.match_file(rel_path):
                continue

            full_path = project_dir / rel_path
            try:
                if full_path.stat().st_size > MAX_FILE_SIZE_BYTES:
                    continue
            except OSError:
                continue

            try:
                with full_path.open("r", encoding="utf-8", errors="ignore") as fh:
                    content = fh.read()
            except Exception:
                continue

            pieces.append(
                f"--- START FILE: {rel_path} ---\n{content}\n--- END FILE: {rel_path} ---\n"
            )

            if verbose:
                print("✓", rel_path)

    return "".join(pieces)


def main() -> None:
    ap = argparse.ArgumentParser(
        description="Copy project text files to clipboard / file"
    )
    ap.add_argument(
        "project_dir", nargs="?", default=".", help="Project directory (default: .)"
    )
    ap.add_argument(
        "-w",
        "--write",
        nargs="?",
        const=DEFAULT_OUTPUT_FILE,
        metavar="FILE",
        help=f"write collected output to FILE (default: {DEFAULT_OUTPUT_FILE})",
    )
    ap.add_argument(
        "-t", "--tests", action="store_true", help="include tests/ directory"
    )
    ap.add_argument(
        "-v", "--verbose", action="store_true", help="print every included file"
    )
    ns = ap.parse_args()

    if not ns.tests:
        EXCLUDED_DIRS.add("tests")

    project_dir = Path(ns.project_dir).resolve()
    extra_excludes = {ns.write} if ns.write else set()

    output = collect_project_contents(
        project_dir, exclude_extra=extra_excludes, verbose=ns.verbose
    )

    if not output:
        print("No relevant files found – nothing copied.")
        sys.exit(1)

    # clipboard
    if pyperclip:
        try:
            pyperclip.copy(output)
            if ns.verbose:
                print(f"(copied {len(output):,} characters to clipboard)")
        except pyperclip.PyperclipException:
            if ns.verbose:
                print("Warning: could not access the system clipboard.")

    # optional file
    if ns.write:
        out_path = Path(ns.write).resolve()
        out_path.write_text(output, encoding="utf-8")
        print(f"Wrote {len(output):,} characters to {out_path}")

    if not ns.write and not pyperclip:
        # fall‑back: print to stdout if nowhere else
        print(output)


if __name__ == "__main__":
    main()

--- END FILE: sc2.py ---
--- START FILE: metadata.json ---
{
  "name": "AI Code Assistant",
  "description": "An AI-powered chat application to help developers analyze, refactor, and improve their code. The assistant provides actionable suggestions and can generate updated code snippets in real-time.",
  "requestFramePermissions": [],
  "prompt": ""
}
--- END FILE: metadata.json ---
--- START FILE: vite.config.ts ---
import path from 'path';
import { defineConfig, loadEnv } from 'vite';

export default defineConfig(({ mode }) => {
    const env = loadEnv(mode, '.', '');
    return {
      define: {
        'process.env.API_KEY': JSON.stringify(env.GEMINI_API_KEY),
        'process.env.GEMINI_API_KEY': JSON.stringify(env.GEMINI_API_KEY)
      },
      resolve: {
        alias: {
          '@': path.resolve(__dirname, '.'),
        }
      }
    };
});

--- END FILE: vite.config.ts ---
--- START FILE: App.tsx ---
import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Message, MessageRole, MessageType } from './types';
import { getStreamingResponse } from './services/geminiService';
import Header from './components/Header';
import ChatInput from './components/ChatInput';
import ChatMessage from './components/ChatMessage';
import Loader from './components/Loader';

const App: React.FC = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [isStreaming, setIsStreaming] = useState(false);
  const [currentLoaderText, setCurrentLoaderText] = useState('');
  const chatContainerRef = useRef<HTMLDivElement>(null);

  // New state for model selection
  const [provider, setProvider] = useState('google');
  const [model, setModel] = useState('gemini-2.5-flash');

  useEffect(() => {
    if (chatContainerRef.current) {
      chatContainerRef.current.scrollTop = chatContainerRef.current.scrollHeight;
    }
  }, [messages, currentLoaderText]);

  const handleModelChange = useCallback((newProvider: string, newModel: string) => {
    setProvider(newProvider);
    setModel(newModel);
  }, []);

  const handleSend = useCallback(async (text: string) => {
    const userMessage: Message = {
      id: Date.now().toString(),
      role: MessageRole.USER,
      content: text,
      type: null,
      isStreaming: false
    };
    setMessages(prev => [...prev, userMessage]);
    setIsStreaming(true);
    setCurrentLoaderText('Analyzing code...');

    let suggestionMessage: Message | null = null;
    let codeMessage: Message | null = null;

    try {
      const stream = getStreamingResponse(text, null, provider, model);
      for await (const event of stream) {
        if (event.type === 'suggestions_chunk') {
            setCurrentLoaderText('');
            if (!suggestionMessage) {
                const id = `${Date.now()}-sugg`;
                suggestionMessage = { id, role: MessageRole.AI, type: MessageType.SUGGESTION, content: event.content || '', agent: event.agent, isStreaming: true, originalUserMessage: text };
                setMessages(prev => [...prev, suggestionMessage!]);
            } else {
                setMessages(prev => prev.map(m => m.id === suggestionMessage!.id ? { ...m, content: m.content + (event.content || '') } : m));
            }
        } else if (event.type === 'suggestions_end') {
            if (suggestionMessage) {
                setMessages(prev => prev.map(m => m.id === suggestionMessage!.id ? { ...m, isStreaming: false, content: event.fullContent || m.content } : m));
            }
            setCurrentLoaderText('Generating implementation...');
        } else if (event.type === 'generated_code_chunk') {
            setCurrentLoaderText('');
            if (!codeMessage) {
                const id = `${Date.now()}-code`;
                codeMessage = { id, role: MessageRole.AI, type: MessageType.CODE, content: event.content || '', agent: event.agent, isStreaming: true, originalUserMessage: text };
                setMessages(prev => [...prev, codeMessage!]);
            } else {
                setMessages(prev => prev.map(m => m.id === codeMessage!.id ? { ...m, content: m.content + (event.content || '') } : m));
            }
        } else if (event.type === 'stream_end') {
            if (codeMessage) {
                setMessages(prev => prev.map(m => m.id === codeMessage!.id ? { ...m, isStreaming: false } : m));
            }
        } else if (event.type === 'error') {
            setCurrentLoaderText('');
            const errorId = `${Date.now()}-error`;
            const errorMessage: Message = { id: errorId, role: MessageRole.AI, type: MessageType.ERROR, content: event.content || "An unknown error occurred.", agent: event.agent, isStreaming: false, originalUserMessage: text };
            setMessages(prev => [...prev, errorMessage]);
            break; // Stop processing on error
        }
      }
    } catch (error) {
      const errorId = `${Date.now()}-client-error`;
      const errorMessage: Message = { id: errorId, role: MessageRole.AI, type: MessageType.ERROR, content: error instanceof Error ? error.message : "A client-side error occurred.", agent: "Application", isStreaming: false, originalUserMessage: text };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsStreaming(false);
      setCurrentLoaderText('');
    }
  }, [provider, model]);

  const handleRegenerate = useCallback(async (originalMessage: string, suggestions: { agent: string, content: string } | null) => {
    setIsStreaming(true);
    setCurrentLoaderText('Regenerating response...');

    // Remove previous AI responses related to this query
    setMessages(prev => prev.filter(m => m.originalUserMessage !== originalMessage || m.role === MessageRole.USER));

    let suggestionMessage: Message | null = null;
    let codeMessage: Message | null = null;
    
    try {
        const stream = getStreamingResponse(originalMessage, suggestions, provider, model);
        for await (const event of stream) {
            // Same logic as handleSend
             if (event.type === 'suggestions_chunk') {
                setCurrentLoaderText('');
                if (!suggestionMessage) {
                    const id = `${Date.now()}-sugg`;
                    suggestionMessage = { id, role: MessageRole.AI, type: MessageType.SUGGESTION, content: event.content || '', agent: event.agent, isStreaming: true, originalUserMessage: originalMessage };
                    setMessages(prev => [...prev, suggestionMessage!]);
                } else {
                    setMessages(prev => prev.map(m => m.id === suggestionMessage!.id ? { ...m, content: m.content + (event.content || '') } : m));
                }
            } else if (event.type === 'suggestions_end') {
                if (suggestionMessage) {
                    setMessages(prev => prev.map(m => m.id === suggestionMessage!.id ? { ...m, isStreaming: false, content: event.fullContent || m.content } : m));
                }
                setCurrentLoaderText('Generating implementation...');
            } else if (event.type === 'generated_code_chunk') {
                setCurrentLoaderText('');
                if (!codeMessage) {
                    const id = `${Date.now()}-code`;
                    codeMessage = { id, role: MessageRole.AI, type: MessageType.CODE, content: event.content || '', agent: event.agent, isStreaming: true, originalUserMessage: originalMessage };
                    setMessages(prev => [...prev, codeMessage!]);
                } else {
                    setMessages(prev => prev.map(m => m.id === codeMessage!.id ? { ...m, content: m.content + (event.content || '') } : m));
                }
            } else if (event.type === 'stream_end') {
                if (codeMessage) {
                    setMessages(prev => prev.map(m => m.id === codeMessage!.id ? { ...m, isStreaming: false } : m));
                }
            } else if (event.type === 'error') {
                setCurrentLoaderText('');
                const errorId = `${Date.now()}-error`;
                const errorMessage: Message = { id: errorId, role: MessageRole.AI, type: MessageType.ERROR, content: event.content || "An unknown error occurred.", agent: event.agent, isStreaming: false, originalUserMessage: originalMessage };
                setMessages(prev => [...prev, errorMessage]);
                break;
            }
        }
    } catch (error) {
        const errorId = `${Date.now()}-client-error`;
        const errorMessage: Message = { id: errorId, role: MessageRole.AI, type: MessageType.ERROR, content: error instanceof Error ? error.message : "A client-side error occurred.", agent: "Application", isStreaming: false, originalUserMessage: originalMessage };
        setMessages(prev => [...prev, errorMessage]);
    } finally {
        setIsStreaming(false);
        setCurrentLoaderText('');
    }
  }, [provider, model]);

  return (
    <div className="bg-slate-900 text-slate-300 flex justify-center items-center min-h-screen font-sans">
      <img src="/LIKIO_FLOW.png" alt="LIKIO FLOW Logo" className="fixed top-[0.5vh] left-[1vw] w-[32vw] max-w-[500px] opacity-90 pointer-events-none z-0 hidden lg:block" />
      <img src="/cat_gato.png" alt="A friendly cat illustration" className="fixed bottom-[25vh] right-[2vw] w-[22vw] max-w-[400px] opacity-90 pointer-events-none z-0 hidden lg:block rounded-[15px]" />
      
      <div className="w-full max-w-4xl h-[96vh] flex flex-col border border-slate-700 rounded-xl bg-slate-800/80 backdrop-blur-sm overflow-hidden relative z-10 shadow-2xl shadow-black/30 sm:h-screen sm:rounded-none">
        <Header 
          provider={provider}
          model={model}
          onModelChange={handleModelChange}
          isStreaming={isStreaming}
        />
        <main ref={chatContainerRef} className="flex-1 p-4 overflow-y-auto flex flex-col gap-4 scroll-smooth">
          {messages.map(msg => (
            <ChatMessage key={msg.id} message={msg} onRegenerate={handleRegenerate}/>
          ))}
          {currentLoaderText && <Loader text={currentLoaderText} />}
        </main>
        <ChatInput onSend={handleSend} isStreaming={isStreaming} />
      </div>
    </div>
  );
};

export default App;

--- END FILE: App.tsx ---
--- START FILE: services/geminiService.ts ---
import { GoogleGenAI } from "@google/genai";
import { StreamEvent } from '../types';

if (!process.env.API_KEY) {
  throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

const SUGGESTION_PROMPT = `You are an expert code reviewer. Your task is to analyze the user's code and provide 3-5 high-impact, actionable improvement suggestions. Focus on clarity, bug prevention, and efficiency.

**Instructions:**
1.  **Do NOT rewrite the code.** Only provide suggestions.
2.  Format your response as a concise Markdown bulleted list.
3.  Keep suggestions focused and easy to implement.

Example:
*   **Refactor for Clarity:** The function \`processData\` is too long. Consider splitting it into smaller, more focused functions like \`validateInput\` and \`transformData\`.
*   **Add Type Hinting:** The function signature lacks type hints. Adding them (e.g., \`def process_data(items: list[str]) -> list[dict]:\`) will improve readability and allow static analysis.
*   **Handle Edge Cases:** The loop does not account for an empty \`items\` list, which could lead to unexpected behavior. Add a check at the beginning.
`;

const GENERATION_SYSTEM_PROMPT = `You are an expert AI programmer. Your task is to refactor and improve the user's original code based on a provided list of suggestions.

**Instructions:**
1.  Implement the changes described in the suggestions.
2.  Return the **FULL, UPDATED CODE** only.
3.  Wrap the final code in a single Markdown code fence. If the language is identifiable, specify it (e.g., \`\`\`python).
4.  **Do not include any commentary, explanations, or apologies outside the code fence.** Your output should be only the code itself.
`;

async function* streamSuggestions(code: string, model: string): AsyncGenerator<StreamEvent> {
  let fullContent = "";
  try {
    const stream = await ai.models.generateContentStream({
      model: model,
      contents: [{ role: 'user', parts: [{text: code}] }, { role: 'model', parts: [{text: SUGGESTION_PROMPT}] }],
    });

    for await (const chunk of stream) {
      const delta = chunk.text;
      if (delta) {
        fullContent += delta;
        yield { type: 'suggestions_chunk', agent: model, content: delta };
      }
    }
    yield { type: 'suggestions_end', agent: model, fullContent };
  } catch (error) {
    console.error("Gemini suggestion error:", error);
    yield { type: 'error', agent: model, content: error instanceof Error ? error.message : "An unknown error occurred" };
  }
}

async function* streamGeneratedCode(userCode: string, suggestions: string, model: string): AsyncGenerator<StreamEvent> {
  const prompt = `
${GENERATION_SYSTEM_PROMPT}

<original_code>
${userCode}
</original_code>

<suggestions>
${suggestions}
</suggestions>
`;

  try {
    const stream = await ai.models.generateContentStream({
        model: model,
        contents: prompt
    });

    for await (const chunk of stream) {
      const delta = chunk.text;
      if (delta) {
        yield { type: 'generated_code_chunk', agent: model, content: delta };
      }
    }
    yield { type: 'stream_end', agent: model };
  } catch (error) {
    console.error("Gemini generation error:", error);
    yield { type: 'error', agent: model, content: error instanceof Error ? error.message : "An unknown error occurred" };
  }
}

export async function* getStreamingResponse(
  userCode: string,
  cachedSuggestions: { agent: string, content: string } | null,
  provider: string,
  model: string
): AsyncGenerator<StreamEvent> {
    if (provider !== 'google') {
        const agentName = `${provider.charAt(0).toUpperCase() + provider.slice(1)} / ${model}`;
        yield { type: 'error', agent: agentName, content: `The '${provider}' provider is not yet implemented in this application.` };
        return;
    }
  
    if (cachedSuggestions) {
    // Phase 2 only: Generate code from cached suggestions
    yield* streamGeneratedCode(userCode, cachedSuggestions.content, model);
  } else {
    // Phase 1: Get suggestions
    let suggestionText = '';
    const suggestionEvents: StreamEvent[] = [];
    for await (const event of streamSuggestions(userCode, model)) {
      suggestionEvents.push(event);
      if (event.type === 'suggestions_end' && event.fullContent) {
        suggestionText = event.fullContent;
      }
      yield event;
    }

    // Check if suggestion phase ended in an error
    const hasError = suggestionEvents.some(e => e.type === 'error');
    if (hasError || !suggestionText) {
      console.warn("Skipping code generation due to suggestion failure or empty suggestions.");
      return;
    }

    // Phase 2: Generate code
    yield* streamGeneratedCode(userCode, suggestionText, model);
  }
}

--- END FILE: services/geminiService.ts ---
--- START FILE: components/Loader.tsx ---

import React from 'react';

interface LoaderProps {
  text: string;
}

const Loader: React.FC<LoaderProps> = ({ text }) => {
  return (
    <div className="self-start flex items-center gap-3 bg-slate-900 border border-slate-700 py-3 px-4 rounded-2xl w-fit">
      <div className="flex space-x-1.5">
        <span className="w-2.5 h-2.5 rounded-full bg-slate-400 animate-pulse" style={{ animationDelay: '-0.3s' }}></span>
        <span className="w-2.5 h-2.5 rounded-full bg-slate-400 animate-pulse" style={{ animationDelay: '-0.15s' }}></span>
        <span className="w-2.5 h-2.5 rounded-full bg-slate-400 animate-pulse"></span>
      </div>
      <span className="text-slate-400 text-sm">{text}</span>
    </div>
  );
};

export default Loader;

--- END FILE: components/Loader.tsx ---
--- START FILE: components/ChatInput.tsx ---

import React, { useState, useRef, useEffect } from 'react';
import { SendIcon } from './icons';

interface ChatInputProps {
  onSend: (message: string) => void;
  isStreaming: boolean;
}

const ChatInput: React.FC<ChatInputProps> = ({ onSend, isStreaming }) => {
  const [text, setText] = useState('');
  const textareaRef = useRef<HTMLTextAreaElement>(null);

  const handleSend = () => {
    const trimmedText = text.trim();
    if (trimmedText) {
      onSend(trimmedText);
      setText('');
    }
  };

  const handleKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  useEffect(() => {
    const textarea = textareaRef.current;
    if (textarea) {
      textarea.style.height = 'auto';
      textarea.style.height = `${textarea.scrollHeight}px`;
    }
  }, [text]);

  return (
    <footer className="flex gap-3 p-3 border-t border-slate-700 bg-slate-800">
      <textarea
        ref={textareaRef}
        value={text}
        onChange={(e) => setText(e.target.value)}
        onKeyDown={handleKeyDown}
        placeholder="Paste code or ask… (Shift+Enter = newline)"
        rows={1}
        className="flex-1 resize-none min-h-[3rem] max-h-40 p-3 border border-slate-700 rounded-2xl bg-slate-900 text-slate-200 focus:outline-none focus:ring-2 focus:ring-green-500 transition-all"
        disabled={isStreaming}
      />
      <button
        onClick={handleSend}
        disabled={isStreaming || !text.trim()}
        className="flex-shrink-0 w-12 h-12 bg-green-500 rounded-full text-white flex items-center justify-center transition-colors hover:bg-blue-500 disabled:opacity-60 disabled:cursor-not-allowed"
        aria-label="Send message"
      >
        <SendIcon />
      </button>
    </footer>
  );
};

export default ChatInput;

--- END FILE: components/ChatInput.tsx ---
--- START FILE: components/ChatMessage.tsx ---

import React, { useEffect, useRef, useState, useCallback } from 'react';
import ReactDOM from 'react-dom/client';
import { Message, MessageType, MessageRole } from '../types';
import { CopyIcon, CheckIcon } from './icons';

declare global {
  interface Window {
    marked: {
      parse(markdown: string): string;
    };
    hljs: {
      highlightElement(element: HTMLElement): void;
    };
  }
}

interface ChatMessageProps {
  message: Message;
  onRegenerate: (originalMessage: string, suggestions: { agent: string, content: string } | null) => void;
}

const ChatMessage: React.FC<ChatMessageProps> = ({ message, onRegenerate }) => {
  const contentRef = useRef<HTMLDivElement>(null);
  const { role, type, content, agent, isStreaming, originalUserMessage } = message;

  useEffect(() => {
    if (contentRef.current && content) {
      if (role === MessageRole.USER) {
        // For user messages, display as pre-formatted text
        const pre = document.createElement('pre');
        const code = document.createElement('code');
        code.textContent = content;
        pre.className = 'bg-transparent p-0';
        pre.appendChild(code);
        contentRef.current.innerHTML = ''; // Clear previous content
        contentRef.current.appendChild(pre);
      } else {
        // For AI messages, parse as Markdown
        contentRef.current.innerHTML = window.marked.parse(content);
      }
      
      // Apply syntax highlighting and add copy buttons
      contentRef.current.querySelectorAll('pre code').forEach((codeBlock) => {
        const preElement = codeBlock.parentElement as HTMLPreElement;
        if (preElement.querySelector('.copy-btn-container')) return; // Already processed

        window.hljs.highlightElement(codeBlock as HTMLElement);
        
        const container = document.createElement('div');
        container.className = 'copy-btn-container absolute top-2 right-2';
        preElement.classList.add('relative');
        preElement.appendChild(container);

        const CopyButton: React.FC = () => {
          const [isCopied, setIsCopied] = useState(false);
          const handleClick = () => {
            navigator.clipboard.writeText(codeBlock.textContent || '').then(() => {
              setIsCopied(true);
              setTimeout(() => setIsCopied(false), 2000);
            });
          };

          return (
            <button
              onClick={handleClick}
              className="copy-btn flex items-center justify-center text-xs py-1 px-2 bg-green-700/80 border border-slate-600 rounded cursor-pointer text-slate-200 hover:bg-green-600/80 disabled:opacity-50"
              disabled={isCopied}
            >
              {isCopied ? <><CheckIcon /> Copied</> : <><CopyIcon /> Copy</>}
            </button>
          );
        };
        
        // This is a way to render React component into a vanilla DOM element
        const root = ReactDOM.createRoot(container);
        root.render(<CopyButton />);
      });
    }
  }, [content, role]);

  const handleRegenerateClick = useCallback(() => {
    if (!originalUserMessage) return;
    // Passing null for the `suggestions` parameter tells the App component
    // to start the AI interaction from the beginning (i.e., fetch new suggestions).
    // This provides a consistent and predictable user experience for regeneration.
    onRegenerate(originalUserMessage, null);
  }, [onRegenerate, originalUserMessage]);

  const baseClasses = "max-w-[90%] py-3 px-4 rounded-2xl relative break-words";
  const roleClasses = {
    [MessageRole.USER]: "bg-blue-600 text-white self-end rounded-br-md",
    [MessageRole.AI]: "bg-slate-800 self-start",
    [MessageRole.SYSTEM]: "hidden",
  };
  const typeClasses = {
    [MessageType.SUGGESTION]: "border-l-4 border-green-500",
    [MessageType.CODE]: "border-l-4 border-blue-400",
    [MessageType.ERROR]: "bg-red-500/20 border-l-4 border-red-500 text-red-200",
  };

  const finalClasses = `${baseClasses} ${roleClasses[role]} ${type ? typeClasses[type] : ''}`;

  return (
    <div className={finalClasses}>
      {agent && role === MessageRole.AI && (
        <p className="text-xs font-semibold text-slate-400 mb-2 uppercase tracking-wider">{agent}</p>
      )}
      <div ref={contentRef} className="prose prose-sm prose-invert max-w-none prose-p:my-2 prose-ul:my-2 prose-ol:my-2 prose-pre:bg-slate-900/70 prose-pre:my-3 prose-pre:p-3 prose-pre:rounded-lg"></div>
      {isStreaming && <span className="inline-block w-2 h-4 bg-slate-300 animate-pulse ml-1"></span>}
      {(!isStreaming && (type === MessageType.SUGGESTION || type === MessageType.CODE || type === MessageType.ERROR)) && (
        <div className="mt-3 pt-3 border-t border-slate-700/50 text-right">
          <button onClick={handleRegenerateClick} className="text-sm py-1.5 px-3 bg-slate-700 text-slate-200 border border-slate-600 rounded-md hover:bg-green-500 hover:text-white transition-colors duration-200">
            Regenerate
          </button>
        </div>
      )}
    </div>
  );
};

export default ChatMessage;
--- END FILE: components/ChatMessage.tsx ---
--- START FILE: components/Header.tsx ---
import React from 'react';
import ModelSelector from './ModelSelector';

interface HeaderProps {
  provider: string;
  model: string;
  onModelChange: (provider: string, model: string) => void;
  isStreaming: boolean;
}

const Header: React.FC<HeaderProps> = ({ provider, model, onModelChange, isStreaming }) => {
  return (
    <header className="flex items-center justify-between p-3 bg-green-500 text-white shadow-md flex-wrap gap-2">
      <h1 className="m-0 text-lg font-medium">AI Code Assistant</h1>
      <ModelSelector
        provider={provider}
        model={model}
        onModelChange={onModelChange}
        isStreaming={isStreaming}
      />
    </header>
  );
};

export default Header;

--- END FILE: components/Header.tsx ---
--- START FILE: components/icons.tsx ---

import React from 'react';

export const SendIcon = () => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 24 24"
    width="24"
    height="24"
    fill="currentColor"
  >
    <path d="M3.4 2.4a.8.8 0 00-.99.99l2.61 8.48H14a.8.8 0 010 1.6H5.02l-2.61 8.49a.8.8 0 00.99.99l19.64-9.56a.8.8 0 000-1.3A64.52 64.52 0 003.4 2.4z" />
  </svg>
);

export const CopyIcon = () => (
    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className="mr-1">
        <rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect>
        <path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path>
    </svg>
);

export const CheckIcon = () => (
    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="3" strokeLinecap="round" strokeLinejoin="round" className="mr-1">
        <path d="M20 6 9 17l-5-5"></path>
    </svg>
);

--- END FILE: components/icons.tsx ---
--- START FILE: components/ModelSelector.tsx ---
import React from 'react';

interface ModelSelectorProps {
  provider: string;
  model: string;
  onModelChange: (provider: string, model: string) => void;
  isStreaming: boolean;
}

const MODELS: { [key: string]: string[] } = {
  google: ['gemini-2.5-flash', 'gemini-2.5-pro'],
  openai: ['gpt-4.1-nano-2025-04-14', 'o4-mini-2025-04-16'],
};

const ModelSelector: React.FC<ModelSelectorProps> = ({ provider, model, onModelChange, isStreaming }) => {
  const handleProviderChange = (e: React.ChangeEvent<HTMLSelectElement>) => {
    const newProvider = e.target.value;
    const newModel = MODELS[newProvider][0]; // default to the first model of the new provider
    onModelChange(newProvider, newModel);
  };

  const handleModelChange = (e: React.ChangeEvent<HTMLSelectElement>) => {
    const newModel = e.target.value;
    onModelChange(provider, newModel);
  };

  return (
    <div className="flex items-center gap-2">
      <div className="flex flex-col">
        <label htmlFor="provider-select" className="text-xs text-green-100/80 capitalize">Provider</label>
        <select
          id="provider-select"
          value={provider}
          onChange={handleProviderChange}
          disabled={isStreaming}
          className="bg-green-600 border border-green-700 text-white text-sm rounded-md focus:ring-green-400 focus:border-green-400 block p-1.5 disabled:opacity-70"
          aria-label="Select AI Provider"
        >
          {Object.keys(MODELS).map(p => <option key={p} value={p}>{p.charAt(0).toUpperCase() + p.slice(1)}</option>)}
        </select>
      </div>
      <div className="flex flex-col">
        <label htmlFor="model-select" className="text-xs text-green-100/80 capitalize">Model</label>
        <select
          id="model-select"
          value={model}
          onChange={handleModelChange}
          disabled={isStreaming}
          className="bg-green-600 border border-green-700 text-white text-sm rounded-md focus:ring-green-400 focus:border-green-400 block p-1.5 disabled:opacity-70"
          aria-label="Select AI Model"
        >
          {MODELS[provider].map(m => <option key={m} value={m}>{m}</option>)}
        </select>
      </div>
    </div>
  );
};

export default ModelSelector;

--- END FILE: components/ModelSelector.tsx ---
